---
title: "Analysis of the used cars dataset"
author: ""
date: "today"
# date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
knitr::opts_chunk$set(warning = F, results = "markup", message = F)
# knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

## Data Import and Cleaning
```{r cars, include=FALSE}

df = read.csv("cars.csv", header = T, stringsAsFactors = TRUE)

df = subset(df, select=c("manufacturer_name", "model_name", "transmission", "color", "odometer_value", "year_produced", "engine_fuel", "engine_has_gas", "engine_type", "engine_capacity", "body_type", "has_warranty",
"state", "drivetrain", "price_usd", "is_exchangeable", "number_of_photos",  "up_counter"))
names(df)[names(df) == 'price_usd'] <- 'price'

```




## Renaming features
```{r include=FALSE}
names(df)[names(df) == 'price_usd'] <- 'price'
```


Checking for the the factors and numerical features   
```{r include=FALSE}
str(df)
```
Looks perfectly fine

## Data Preprocessing
```{r include=FALSE}
colSums(is.na(df))
```

Engine Capacity has 10 null values, we dropped the rows with null values.
```{r include=FALSE}
#Droping the rows with null values 
df <- df[complete.cases(df), ]
```

## Summary of Dataset
```{r include=FALSE}
library(corrplot)
library(tidyverse)

df %>% select_if(is.numeric)->cars_numerical
```


•	The Dataset used for the project is “Belarus-Used-cars-catalog” taken from the public data source Kaggle (An online community of data scientists and machine learning practitioners).

  Link: https://www.kaggle.com/lepchenkov/usedcarscatalog?select=cars.csv

•	The Dataset contains information about the Belarus (western Europe) used cars market from the year 2019.

•	The total number of variables in the data set is 19.

•	The total number of observations in the data set is 38521.

•	This Dataset helps the team in exploring the used car market in Belarus and build a model to find the relationship between car prices with changing features that can effectively predict the price of a used car, given the certain parameters (both numerical and categorical).

•	From the Dataset we mainly focus on these features as mentioned below to perform Exploratory Data Analysis:

  •	Color
  •	Transmission
  •	Odometer value
  •	Year of Production
  •	Body type
  •	Number of Photos
  •	Duration of days


### Limitations of Dataset:
1.	The “Belarus-Used-cars-catalog” dataset is limited to only Belarus which in effect does not help Pattern 6 to make assumptions about used car markets in other countries.

2.	There is no ‘electric’ car category as the dataset is limited to gasoline and diesel.

3.	There could have been more features found in the dataset which Team Pattern 6 could have used for the Exploratory Data Analysis and get a more detailed analysis when comparing multiple features.



## Exploratory Data Analysis
```{r echo=TRUE}
# summary(cars_numerical)
library(fBasics)
basicStats(cars_numerical)
```

The table above gives us the basic statistic measures of numeric data. There are six numerical variables in our dataset. The one we care about most is the used car's price. It has mean=6640, standard deviation(sd)=6430. The odometer_value with mean=249000, sd=136000. The year_produced with mean=2000 and sd=8.06. The engine_capacity has mean=2.06 and sd=0.67. The absolute values of skewness for all the variables are all greater than 1, which indicates they are highly skewed. The kurtosis values are all greater than 0, indicating they are sharply peaked with heavy tails. More analysis between other variables shows below.

## Normality tests

This section checks the normality of numerical variables based on the Q-Q plot, histogram, and normality tests. The most common method for normality test is called *Shapiro-Wilk's method*, however, this test only works when the observation is less than 5000,and our data set is more extensive than this value, so a *Kolmogorov-Smirnov (K-S) normality test* will be used instead.

```{r, fig.height=3}
library(gridExtra)
plot1 = ggplot(cars_numerical, aes(sample = price)) + stat_qq(col="#00AFBB") + stat_qq_line() + labs(title = 'Q-Q plot of price') 
plot2 = ggplot(cars_numerical, aes(x = price)) + geom_histogram(fill = "#00AFBB", colour="white", bins=40) + labs(title = 'Histogram of price')

grid.arrange(plot1, plot2, ncol=2, nrow=1)
```

As it could be found in the quantile-quantile plot and the histogram,`price` are not normally distributed, if PatternSix wants to use the price as the dependent variable for a linear regression, it is necessary to transform it to a normal distribution after that.

```{r}
plot3 = ggplot(cars_numerical, aes(sample = odometer_value)) + stat_qq(col="#00AFBB") + stat_qq_line() + labs(title = 'Q-Q plot of odometer_value')
plot4 = ggplot(cars_numerical, aes(x = odometer_value)) + geom_histogram(fill = "#00AFBB", colour="white", bins=40) + labs(title = 'Histogram of odometer_value')

plot5 = ggplot(cars_numerical, aes(sample = year_produced)) + stat_qq(col="#00AFBB") + stat_qq_line() + labs(title = 'Q-Q plot of year_produced')
plot6 = ggplot(cars_numerical, aes(x = year_produced)) + geom_histogram(fill = "#00AFBB", colour="white", bins=40) + labs(title = 'Histogram of year_produced')

grid.arrange(plot3, plot4, plot5, plot6, ncol=2, nrow=2)
```

```{r}
plot7 = ggplot(cars_numerical, aes(sample = engine_capacity)) + stat_qq(col="#00AFBB") + stat_qq_line() + labs(title = 'Q-Q plot of engine_capacity')
plot8 = ggplot(cars_numerical, aes(x = engine_capacity)) + geom_histogram(fill = "#00AFBB", colour="white", bins=40) + labs(title = 'Histogram of engine_capacity')

plot9 = ggplot(cars_numerical, aes(sample = number_of_photos)) + stat_qq(col="#00AFBB") + stat_qq_line() + labs(title = 'Q-Q plot of number_of_photos')
plot10 = ggplot(cars_numerical, aes(x = number_of_photos)) + geom_histogram(fill = "#00AFBB", colour="white", bins=40) + labs(title = 'Histogram of number_of_photos')

grid.arrange(plot7, plot8, plot9, plot10, ncol=2, nrow=2)
```

The Q-Q plots and histograms also show evidence of non-normality. The `odometer_value`, `engine_capacity` and `number_of_photos` are right-skewed, while `year_produced` is left-skewed.

Now let's apply *Kolmogorov-Smirnov normality test* into our data. The null hypothesis of this test is 'sample distribution is normal'.

```{r, warning=FALSE}
ks.test(df$price, 'pnorm', mean=mean(df$price), sd=sd(df$price))
ks.test(df$odometer_value, 'pnorm', mean=mean(df$odometer_value), sd=sd(df$odometer_value))
ks.test(df$year_produced, 'pnorm', mean=mean(df$year_produced), sd=sd(df$year_produced))
ks.test(df$engine_capacity, 'pnorm', mean=mean(df$engine_capacity), sd=sd(df$engine_capacity))
ks.test(df$number_of_photos, 'pnorm', mean=mean(df$number_of_photos), sd=sd(df$number_of_photos))
```

The p-value of all the numeric variables are < 2e-16 which is less than 0.05, therefore it could be concluded that the distributions of all our numeric variables are significantly different from normal distribution. They have the same results with Q-Q plots and histograms.

Our sample size for this data is 38521. Based on the central limit theorem, the rest analysis will be generated using the original data.



## SMART Qeustions
The following are our SMART questions

**Specific**: Is it possible to build a model to find a relationship between car prices by looking at different factors that include numerical, categorical values and further use the model to predict car prices?

**Measurable**: Is it possible to measure metrics such as r-square, MAE, MSE and RMSE with your categories?

**Achievable**: Based on the preliminary analysis that the team concluded is it possible to find a pattern between target variable(car price) and the independent variable?

**Relevant**: Can the research help the sellers and buyers in the used car market to make an informed decision about the price of the vehicle?

**Time Oriented**: Will The initial analysis be completed by November, 2nd with the presentation?






## Correlation Plot

```{r Fig 1}
corrplot(cor(cars_numerical), method = 'number')
```
Figure 1 shows the correlation between the numerical features.

The team used a correlation plot for checking the correlation between continuous variables. Year of production was highly correlated with price with correlation coefficient(cc)=0.7. Odometer value had a negative correlation with year produced (cc=-0.49) and price (cc=-0.42). Engine capacity also had a positive correlation with price (cc=0.30). 


```{r Fig. 2}
library(ggplot2)

df %>% group_by(year_produced) %>% summarize(mean_price_per_year = mean(price, na.rm=TRUE)) %>% ggplot(aes(x=year_produced,y=mean_price_per_year)) +  geom_col(fill = "#00AFBB") + labs(title='Avg Price of Car per Year', x="year produced", y = "mean price per year") + theme(plot.title = element_text(hjust = 0.5))
```

Figure 2 shows the average price of the car for each year produced between 1940 and 2020. The team observed that there is a steady decrease in the price as the car gets older. However around 1990, it could be observed that the prices spike as cars before 1990 fall under the classic or vintage category.

The bar plot of the average price of the car in different years showed that the vintage cars produced around the year 1965 are pricier than the newer cars. And the price increased steadily after around 1985.


```{r Fig. 3}
df %>% group_by(engine_capacity) %>% summarize(mean_price_per_capicity = mean(price, na.rm=TRUE)) %>% ggplot(aes(x=engine_capacity,y=mean_price_per_capicity)) +  geom_point(color = "#00AFBB") + labs(title='Avg Price of Car for engine capacity', x='Engine Capacity', y='Mean Price') + theme(plot.title = element_text(hjust = 0.5))
```
Figure 3 shows the average price of the car for each engine capacity. 
The team observed a positive linear trend between the mean price per engine capacity and the capacity 



```{r}
df %>% group_by(engine_capacity) %>% summarize(mean_price_per_capacity = mean(price, na.rm=TRUE)) ->df4
cor(df4)
#corrplot(cor(cars_numerical), method = 'number')
```

The observed correlation coefficient equals 0.6. However, in Figure 1 it was observed that the correlation coefficient between price and engine capacity was 0.3. This trend could be explained by the outliers which are found in higher engine capacity.



```{r Fig 4}
df %>% group_by(engine_capacity) %>% summarize(mean_price_per_capacity = mean(price, na.rm=TRUE)) ->df4
cor(df4)
#corrplot(cor(cars_numerical), method = 'number')
```

```{r}
df %>% ggplot(aes(x=reorder(body_type,-engine_capacity),y=engine_capacity, fill=body_type))+geom_boxplot() + labs(x='Body Type', y='Engine Capicity')  + ggtitle('Body Type vs Engine Capicity ') + theme(plot.title = element_text(hjust = 0.5))
```

Figure 4 shows the mean engine capacity for different body type using a box-plot. From the initial analysis the team observed for each of the groups there is a difference in median.


## T test

When there are two samples drawn from the same population and the goal is to test whether the mean of respective two samples are the same, it is wise to perform the student-t test, or t-test in short. The reason team PatternSix did not choose the Z-test is that the team did not know the population standard deviation. Thus using t-test, team used sample standard deviation (s) to estimate the population parameter (σ).


### Warranty vs Price
PatternSix tested some of the features against prices respectively since price is going to be the dependent variable. First one the team looked at is whether cars had warranties versus different average prices. A box-plot would help show the relationship between these two.


```{r}
df %>% ggplot(aes(has_warranty, price, fill=has_warranty)) + geom_boxplot() + ggtitle('Has_Warranty vs Prices ') + theme(plot.title = element_text(hjust = 0.5))
```
From the graph, one could see that the average prices differ significantly between warrantied and non-warrantied cars.

The t-test was performed to verify the assumptions.

```{r T test, echo=TRUE}
summary(df$has_warranty)
has = subset(df, has_warranty == "True")
hasnot = subset(df, has_warranty == "False")
t.test(x = has$price, y = hasnot$price, conf.level = 0.99)
```

PatternSix subset the prices for cars based on whether they have warranties. The null hypothesis H0 is that μ1 = μ2. The alternative hypothesis H1 is μ1 <> μ2. From the result, because p-value is extremely low, team rejects the null hypothesis and concludes that whether cars have warranties does affect average price of cars.


###  Engine Types vs Price

Next, lets take a look at whether different engine types have different average prices. same as above, PatternSix drew a box-plot to get a visual idea.

```{r}
df %>% ggplot(aes(engine_type, price,fill=engine_type)) + geom_boxplot()+ ggtitle('Engine_type vs Prices ') + theme(plot.title = element_text(hjust = 0.5))
```

This time, from the graph, PatternSix could not get a conclusion right away. That is why it is crucial to perform the formal test.


```{r echo=TRUE}
summary(df$engine_type)
diesel = subset(df, subset = df$engine_type == "diesel")
gas = subset(df, subset = df$engine_type == "gasoline")
t.test(x = diesel$price, y = gas$price, conf.level = 0.99)
```

PatternSix subset prices for cars based on different engine types. The null hypothesis H0 is μ1 = μ2. The null hypothesis is μ1 <> μ2.

Surprisingly, the p-value is extremely low, which tells the team to reject the null hypothesis and  conclude for different engine types, their average prices do differ.



## $Chi^2$ test

In the data set, not only do there are numerical variables,but there are also categorical variables.
For categorical variables, data set does not fit the requirements for goodness of fit test but the data has to be tested for colinearity between categorical variables for variable selection in model building. Test of Independence thus is performed. 


```{r}
contgcTbl1 = table(df$manufacturer_name, df$has_warranty)

(Xsq1 = chisq.test(contgcTbl1))


contgcTbl2 = table(df$manufacturer_name, df$body_type)

(Xsq2 = chisq.test(contgcTbl2))

contgcTbl3 = table(df$manufacturer_name, df$color)

(Xsq3 = chisq.test(contgcTbl3))

contgcTbl4 = table(df$color, df$transmission)

(Xsq4 = chisq.test(contgcTbl4))
summary(Xsq4)

contgcTbl5 = table(df$manufacturer_name, df$is_exchangeable)
(Xsq5 = chisq.test(contgcTbl5))


```

The pairs that were chosen here are different manufacturers versus whether cars have warranties, different body types, different colors and whether cars are exchangable, respectively. In addition, the test between different colors and whether the car is automatic or manual is also conducted. To make presenting results easier, these tests are assigned as 1, 2, 3, 4, 5 respectively. One thing to note here is that for the last test, to put which variable in row position or column position does not matter as a result of non casualty between them.


PatternSix's null hypotheses are that all pairs are independent. Interestingly, wide range of results can be observed. For test 1, 2, 3, a warning that the chi-square test approximation might be incorrect pops up. The reason for that is to use the test of independence, sample size has to be large enough. General rule is that if expected frequencies for 20% of the categories are less than 5,it can't be used to test independence. That is exactly what happened here. As a result, these test results can't be used.

For test 4, between different manufacturers and whether cars are exchangable, and for test 5, between different colors and whether the car is automatic or manual, the results are acceptable. Due to low p-values in both tests, the null hypothesis has been rejected, which means for test 4 and 5 testing pairs, they are not independent.


## ANOVA 

Due to the fact that there are numerous independent variables to test on, in order to improve efficiency, ANOVA was performed.

Same as above, a graph would give the observer an overview of relationships against prices.

### Colors by Mean Price
```{r}
df %>% group_by(color) %>% summarise(price_colorMean=mean(price)) %>% ggplot(aes(x=reorder(color,-price_colorMean),y=price_colorMean)) + geom_col(fill = "#00AFBB") + labs(x='Color',y='Price mean') + ggtitle('Color vs Prices ') + theme(plot.title = element_text(hjust = 0.5))
```

### Body Types by Mean Price
```{r}
df %>% group_by(body_type) %>% summarise(body_price_mean = mean(price))%>% ggplot(aes(x = reorder(body_type, -body_price_mean),body_price_mean))+geom_col(fill = "#00AFBB") + labs(x='Body Type', y='Mean of price') + ggtitle('Body Type vs Price ') + theme(plot.title = element_text(hjust = 0.5))
```

### Top 10 Manufacturers by Mean Price
```{r}
df2 = df %>% group_by(manufacturer_name) %>% summarise(manuf_price_mean = mean(price)) %>% arrange(desc(manuf_price_mean)) 
df2 %>% slice(1:10) %>%  ggplot(aes(x = reorder(manufacturer_name, -manuf_price_mean),manuf_price_mean))+geom_col(fill = "#00AFBB") + labs(x='Manufacturer', y='Mean of price')  + ggtitle('Manufacturer vs Price ') + theme(plot.title = element_text(hjust = 0.5))
```

Here there are three graphs, average prices for different colors, for different body types and for top ten manufacturers. The last one is showing limited data by reason of display limitations.

It could be seen that average price differences are all significant between groups in colors, body types and top ten manufacturers. Same as the t-test,a formal test should be performed to get correct conclusions.


### One Way ANOVA
```{r}
df_aov_1 = aov(price ~  color , df)
summary(df_aov_1)

df_aov_2 = aov(price ~  manufacturer_name , df)
summary(df_aov_2)

df_aov_2 = aov(price ~  body_type , df)
summary(df_aov_2)

```

Pairs that were chosen here are prices versus different colors, different manufacturers and different body types, respectively. PatternSix's null hypotheses are that for all pairs, they are independent, same as the $Chi^2$ test. Because there are multiple categories for categorical variables for this test, the alternative hypotheses are that all these categories are not all same. 

For all three cases, in accordance with the extreme low p-values, the null hypotheses is rejected, which means all categories are not all the same within a test.


The Turkey test has been performed in this data set. However, due to excessive levels in categorical variables, it is impractical to incorporate it into the report.

## Conclusion and Discussions
Overall, our work involved removing the null values for data preprocessing, data exploratory, normality check, finding the correlation between continuous variables, and finding the mean price difference between multiple categorical variables. The technologies we used included a table summary, normality tests, t-test, ANOVA, and Chi-square test. We used a variety of plots such as bar plot, scatter plot, box plot, Q-Q plot, and histogram to support different tests.

For more details, we deleted ten null values in the data preprocessing part. Then we generated a table to show the basic statistical measurements of numeric data. The price of this data offers mean=6640 and standard deviation=6430. The other two measurements we may consider are skewness and kurtosis. These two statistical values indicated that the data were highly skewed.

Based on these results, we checked the normality of continuous data by using Q-Q plot, histogram, and Kolmogorov-Smirnov normality test. The normality tests showed significant evidence to reject the null hypothesis. Thus, the price was not a normal distribution. The other continuous variables showed the same results. Therefore, for our future work, if we need to use price as the dependent variable to create a regression, we will transform the data to a normal distribution.

We used a correlation plot for checking the correlation between continuous variables. Year of production was highly correlated with price with correlation coefficient(cc)=0.7. Odometer value had a negative correlation with year produced (cc=-0.49) and price (cc=-0.42). Engine capacity also had a positive correlation with price (cc=0.30).

We then generated other exploratory data analysis for the feature that we were more concerned about – price. 

The bar plot of the average price of the car in different years showed that the vintage cars produced around the year 1965 are pricier than the newer cars. And the price increased steadily after around 1985. The box plots and t-tests suggested the solid statistical significance of the difference between the mean price of vehicles with a warranty and without warranty and diesel and gasoline engine types. In our analysis, one-way and two-way ANOVA were used to check the difference between more than three levels of categorical data and price. The results suggested that color, manufacturer name, and body type had mean price differences.


According to the above analysis, the features that influence the prices of cars in the used car market in Belarus are year of production, body type, manufacture name, engine capacity, odometer value, engine type color, and transmission. 

After conducting the EDA and hypothesis tests on the data, the team has concluded that the initial SMART research question were successful answered.

Our future work for this topic is building up a model to predict the price based on the analysis we explored to provide more effective decision-making services for future vehicle buyers and sellers.


